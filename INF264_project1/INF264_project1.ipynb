{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF264 - Project 1\n",
    "`@authors` Kristin Loka Ã˜ydna and Silje Folkestad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "0. [Imports](#Imports)\n",
    "1. [Reading Dataset](#Reading-Dataset)\n",
    "    1. [Loading Dataset](#Loading-Dataset)\n",
    "    2. [Clean Up](#Clean-Up)\n",
    "2. [Task 1.1 / 1.2 / 1.3](#Task-1.1-/-1.2-/-1.3)\n",
    "    1. [Node Class](#Node-class)\n",
    "    2. [Decision Tree Class](#Decision-tree-class)\n",
    "3. [Train_test_split](#Train_test_split)\n",
    "4. [Task 1.4: Evaluate Algorithm](#Task-1.4)\n",
    "    1. [Model Selection](#Model-Selection)\n",
    "    2. [Model Evaluation](#Model-Evaluation)\n",
    "5. [Task 1.5: Comparing to sklearn.tree.DecisionTreeClassifier](#Task-1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"magic04.data\", header=None, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Export the dataframe to numpy'''\n",
    "X = data.iloc[:, :-1].to_numpy().astype(float)\n",
    "y_temp = data.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['g', 'h'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Checking how many distinct values there are in y_temp'''\n",
    "np.unique(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Changing the values in y_temp to 1 and 0'''\n",
    "y = np.zeros(shape=y_temp.shape)\n",
    "y[y_temp == 'h']=1.0\n",
    "\n",
    "data = np.concatenate((X, np.expand_dims(y,axis=1)), axis = 1)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Checking if there are any missing values'''\n",
    "\n",
    "# Replacing the missing values with np.NaN\n",
    "data.replace(r'^\\s*$', np.NaN, regex=True, inplace = True)\n",
    "\n",
    "# Checking if there are any np.NaN\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1 / 1.2 / 1.3\n",
    "### Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, dominant_label = None, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        '''Constructor'''\n",
    "        self.dominant_label = dominant_label\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self,  impurity_measure):\n",
    "        '''Constructor'''\n",
    "        self.root = None\n",
    "        self.impurity_measure = impurity_measure\n",
    "        \n",
    "    def build_tree(self, dataset):\n",
    "        '''Building the tree'''\n",
    "        X = dataset[:, :-1]\n",
    "        y = dataset[:, -1]\n",
    "    \n",
    "        num_rows, num_feat = np.shape(X)\n",
    "\n",
    "        labels, counts = np.unique(y, return_counts=True)        \n",
    "        freq_label = labels[np.argmax(counts)]\n",
    "        \n",
    "        if labels.shape[0]==1:\n",
    "            return Node(value = y[0])\n",
    "        \n",
    "        elif np.unique(X, axis = 0).shape[0] == 1:\n",
    "            return Node(value = freq_label)\n",
    "        \n",
    "        else:\n",
    "            best_split = self.get_best_split(dataset, num_feat)\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"]) #Recursive \n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"]) #Recursive\n",
    "                return Node(feature_index = best_split[\"feature_index\"], threshold = best_split[\"threshold\"], \n",
    "                            left = left_subtree, right = right_subtree, info_gain = best_split[\"info_gain\"], \n",
    "                            dominant_label = freq_label)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_feat):\n",
    "        '''Finds the best split'''\n",
    "        \n",
    "        best_split={}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        for feature_index in range(num_feat):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            threshold =  np.mean(feature_values)\n",
    "            dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "            if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                curr_info_gain = self.information_gain(y, left_y, right_y, self.impurity_measure)\n",
    "                if curr_info_gain > max_info_gain:\n",
    "                    best_split[\"feature_index\"] = feature_index\n",
    "                    best_split[\"threshold\"] = threshold\n",
    "                    best_split[\"dataset_left\"] = dataset_left\n",
    "                    best_split[\"dataset_right\"] = dataset_right\n",
    "                    best_split[\"info_gain\"] = curr_info_gain\n",
    "                    max_info_gain = curr_info_gain\n",
    "        return best_split\n",
    "        \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        '''Splitting data'''\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    # Task 1.1/1.2\n",
    "    def information_gain(self, parent, l_child, r_child, impurity_measure):\n",
    "        '''Calculating information gain'''\n",
    "        impurity_measure = self.impurity_measure\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if impurity_measure == 'gini':\n",
    "            gain = 1-(self.gini(parent) - (weight_l*self.gini(l_child) + weight_r*self.gini(r_child)))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain    \n",
    "\n",
    "    def entropy(self, y):\n",
    "        '''Calculating entropy'''\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for label in class_labels:\n",
    "            prob_label = len(y[y == label])/len(y)\n",
    "            entropy += -prob_label*np.log2(prob_label)\n",
    "        return entropy\n",
    "\n",
    "    # Task 1.2\n",
    "    def gini(self, y):\n",
    "        '''Calculating gini'''\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for label in class_labels:\n",
    "            prob_label = len(y[y == label])/len(y)\n",
    "            gini += prob_label**2\n",
    "        return gini\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        '''Training the tree'''\n",
    "        dataset = np.concatenate((X, Y), axis = 1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "            \n",
    "    def predicts(self, X):\n",
    "        '''Predicting the new dataset'''\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "        \n",
    "    def make_prediction(self, x, tree):\n",
    "        '''Predicting a new data point'''\n",
    "        if tree.value is not None: \n",
    "            return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "        \n",
    "    #Task 1.3\n",
    "    def reduced_error_pruning(self, node, pruning_dataset):\n",
    "        if node.value is not None:\n",
    "            return np.sum(node.value != pruning_dataset[:, -1])\n",
    "\n",
    "        split_left = pruning_dataset[:,node.feature_index] <= node.threshold\n",
    "        split_right = ~split_left #the opposite of split_left\n",
    "        pruning_dataset_left = pruning_dataset[split_left, :]\n",
    "        pruning_dataset_right = pruning_dataset[split_right, :]\n",
    "        \n",
    "        \n",
    "        error_left = self.reduced_error_pruning(node.left, pruning_dataset_left)\n",
    "        error_right = self.reduced_error_pruning(node.right, pruning_dataset_right)\n",
    "        \n",
    "        error_without_pruning = error_left + error_right\n",
    "        \n",
    "        error_with_pruning = np.sum(node.dominant_label != pruning_dataset[:, -1])\n",
    "        \n",
    "        if error_without_pruning >= error_with_pruning:\n",
    "            node.left = None\n",
    "            node.right = None\n",
    "            node.value = node.dominant_label\n",
    "            return error_with_pruning\n",
    "        else:\n",
    "            return error_without_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_test_split():\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def split_into_training_data(self, dataset):\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        Y = dataset.iloc[:, -1].values.reshape(-1, 1)\n",
    "\n",
    "        X_train, X_val_test, Y_train, Y_val_test = train_test_split(X, Y, test_size = 0.4, shuffle = True, random_state = 42)\n",
    "        X_val, X_test, Y_val, Y_test = train_test_split(X_val_test, Y_val_test, test_size = 0.5, shuffle = True, random_state = 42)\n",
    "        return (X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "    \n",
    "    def split_into_pruning_data(self, X_train, Y_train):\n",
    "        X_after_train, X_prune, Y_after_train, Y_prune = train_test_split(X_train, Y_train, test_size = 0.5, shuffle = True, random_state = 42)\n",
    "        dataset_train = np.concatenate((X_after_train, Y_after_train), axis = 1)\n",
    "        dataset_prune = np.concatenate((X_prune, Y_prune), axis = 1)\n",
    "        return (dataset_train, dataset_prune, X_after_train, Y_after_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = Train_test_split(data)\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = splitter.split_into_training_data(data)\n",
    "dataset_train, dataset_prune, X_after_train, Y_after_train = splitter.split_into_pruning_data(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with entropy: 0.7957413249211357\n"
     ]
    }
   ],
   "source": [
    "'''Entropy accuracy'''\n",
    "classifier = DecisionTree(impurity_measure = \"entropy\")\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predicts(X_val)\n",
    "entropy_without_pruning_acc = accuracy_score(Y_val, Y_pred)\n",
    "print(\"Accuracy score with entropy:\", entropy_without_pruning_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with entropy and pruning: 0.8288643533123028\n"
     ]
    }
   ],
   "source": [
    "'''Entropy accuracy with pruning'''\n",
    "classifier = DecisionTree(impurity_measure = \"entropy\")\n",
    "\n",
    "classifier.fit(X_after_train, Y_after_train)\n",
    "classifier.reduced_error_pruning(classifier.root, dataset_prune)\n",
    "Y_pred = classifier.predicts(X_val)\n",
    "entropy_with_pruning_acc = accuracy_score(Y_val, Y_pred)\n",
    "print(\"Accuracy score with entropy and pruning:\", entropy_with_pruning_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with gini index: 0.7915352260778128\n"
     ]
    }
   ],
   "source": [
    "'''Gini index accuracy'''\n",
    "classifier = DecisionTree(impurity_measure = \"gini\")\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predicts(X_val)\n",
    "gini_without_pruning_acc = accuracy_score(Y_val, Y_pred)\n",
    "print(\"Accuracy score with gini index:\", gini_without_pruning_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with gini index and pruning: 0.8264984227129337\n"
     ]
    }
   ],
   "source": [
    "'''Gini index with pruning'''\n",
    "classifier = DecisionTree(impurity_measure = \"gini\")\n",
    "\n",
    "classifier.fit(X_after_train, Y_after_train)\n",
    "classifier.reduced_error_pruning(classifier.root, dataset_prune)\n",
    "Y_pred = classifier.predicts(X_val)\n",
    "gini_with_pruning_acc = accuracy_score(Y_val, Y_pred)\n",
    "print(\"Accuracy score with gini index and pruning:\", gini_with_pruning_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model that performes the best is entropy with pruning\n"
     ]
    }
   ],
   "source": [
    "'''Checks the highest accuracy score between all of our models'''\n",
    "\n",
    "highest_acc = max(entropy_without_pruning_acc, entropy_with_pruning_acc, gini_without_pruning_acc, gini_with_pruning_acc)\n",
    "\n",
    "acc={\"entropy\":entropy_without_pruning_acc, \"entropy with pruning\":entropy_with_pruning_acc, \n",
    "     \"gini index\":gini_without_pruning_acc, \"gini index with pruning\":gini_with_pruning_acc}\n",
    "\n",
    "print(\"The model that performes the best is\",max(acc, key=acc.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since pruning with entropy gives the best accuracy on the validation dataset, we will use that model to evaluate on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with entropy and pruning on test set: 0.8378023133543638\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTree(impurity_measure = \"entropy\")\n",
    "\n",
    "classifier.fit(X_after_train, Y_after_train)\n",
    "classifier.reduced_error_pruning(classifier.root, dataset_prune)\n",
    "Y_pred = classifier.predicts(X_test)\n",
    "entropy_with_pruning_acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score with entropy and pruning on test set:\", entropy_with_pruning_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score when using existing decision tree implementation: 0.8194006309148265\n"
     ]
    }
   ],
   "source": [
    "'''Calculating accuracy with sklearn.tree.DecisionTreeClassifer'''\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predcls = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score when using existing decision tree implementation:\", accuracy_score(Y_test, Y_predcls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score from our algorithm is better than the accuracy score when using existing decision tree implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
